{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<figure data-vars-mediatype=\"image\"><img alt=\"File Photo: Uber has 65,000 active drivers in the UK (AP)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/5e4f6439ce844ff7bb99d7b82fd9f472-5e4f6439ce844ff7bb99d7b82fd9f472-1_1613730321113_1613730349406.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/5e4f6439ce844ff7bb99d7b82fd9f472-5e4f6439ce844ff7bb99d7b82fd9f472-1_1613730321113_1613730349406.jpg\" style=\"vertical-align: middle;\" title=\"File Photo: Uber has 65,000 active drivers in the UK (AP)\"/><figcaption>File Photo: Uber has 65,000 active drivers in the UK <strong>(AP)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"An employee arranges furniture inside the new IKEA store in Navi Mumbai. (REUTERS)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/2020-12-17T123606Z_1976393528_RC20PK9KT57E_RTRMADP_3_IKEA-INDIA_1608275648703_1608275674446_1613727510452.JPG\" src=\"https://images.livemint.com/img/2021/02/19/600x338/2020-12-17T123606Z_1976393528_RC20PK9KT57E_RTRMADP_3_IKEA-INDIA_1608275648703_1608275674446_1613727510452.JPG\" style=\"vertical-align: middle;\" title=\"An employee arranges furniture inside the new IKEA store in Navi Mumbai. (REUTERS)\"/><figcaption>An employee arranges furniture inside the new IKEA store in Navi Mumbai. <strong>(REUTERS)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"It said the 'Homy' app facilitated 14,155 customer home loan applications since its launch on February 14\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/licfl_1605096188482_1605096387798_1613726422803.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/licfl_1605096188482_1605096387798_1613726422803.jpg\" style=\"vertical-align: middle;\" title=\"It said the 'Homy' app facilitated 14,155 customer home loan applications since its launch on February 14\"/><figcaption>It said the 'Homy' app facilitated 14,155 customer home loan applications since its launch on February 14</figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"OneWeb said that it had raised $500 million from its investors.\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/oneweb-kzjH--621x414@LiveMint_1613725978069.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/oneweb-kzjH--621x414@LiveMint_1613725978069.jpg\" style=\"vertical-align: middle;\" title=\"OneWeb said that it had raised $500 million from its investors.\"/><figcaption>OneWeb said that it had raised $500 million from its investors.<br/></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"Elon Musk posted a meme from the movie ‘The Lion King’, showing himself holding up the cub Simba that’s photoshopped with the Dogecoin logo of a Shiba Inu. (MINT_PRINT)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/bcbb1e86-6707-11eb-af56-581e788aaf84_1613722954234_1613722975090.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/bcbb1e86-6707-11eb-af56-581e788aaf84_1613722954234_1613722975090.jpg\" style=\"vertical-align: middle;\" title=\"Elon Musk posted a meme from the movie ‘The Lion King’, showing himself holding up the cub Simba that’s photoshopped with the Dogecoin logo of a Shiba Inu. (MINT_PRINT)\"/><figcaption>Elon Musk posted a meme from the movie ‘The Lion King’, showing himself holding up the cub Simba that’s photoshopped with the Dogecoin logo of a Shiba Inu. <strong>(MINT_PRINT)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"Muthoot Finance Limited earlier reported a 22 per cent jump in standalone profit after tax at  ₹991.4 crore for the quarter ended December 2020. (Prajakta Patil/Mint)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/muthoot--621x414--621x414--621x414_1613722197999.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/muthoot--621x414--621x414--621x414_1613722197999.jpg\" style=\"vertical-align: middle;\" title=\"Muthoot Finance Limited earlier reported a 22 per cent jump in standalone profit after tax at  ₹991.4 crore for the quarter ended December 2020. (Prajakta Patil/Mint)\"/><figcaption>Muthoot Finance Limited earlier reported a 22 per cent jump in standalone profit after tax at  <span class=\"webrupee\">₹</span>991.4 crore for the quarter ended December 2020. <strong>(Prajakta Patil/Mint)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"FILE PHOTO: The IKEA logo is seen on shopping carts inside the new IKEA store in Navi Mumbai, India, December 17, 2020. REUTERS/Francis Mascarenhas/File Photo (REUTERS)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/2021-01-18T121548Z_2015623784_RC2CAL9KGHGR_RTRMADP_3_INDIA-BUDGET-TAX_1613720983538_1613721008292.JPG\" src=\"https://images.livemint.com/img/2021/02/19/600x338/2021-01-18T121548Z_2015623784_RC2CAL9KGHGR_RTRMADP_3_INDIA-BUDGET-TAX_1613720983538_1613721008292.JPG\" style=\"vertical-align: middle;\" title=\"FILE PHOTO: The IKEA logo is seen on shopping carts inside the new IKEA store in Navi Mumbai, India, December 17, 2020. REUTERS/Francis Mascarenhas/File Photo (REUTERS)\"/><figcaption>FILE PHOTO: The IKEA logo is seen on shopping carts inside the new IKEA store in Navi Mumbai, India, December 17, 2020. REUTERS/Francis Mascarenhas/File Photo <strong>(REUTERS)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"On NSE, it gained 7.40 per cent to  ₹62.40 -- its 52-week high.\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/IDFC_First_Bank_1569238000074_1613720440020.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/IDFC_First_Bank_1569238000074_1613720440020.jpg\" style=\"vertical-align: middle;\" title=\"On NSE, it gained 7.40 per cent to  ₹62.40 -- its 52-week high.\"/><figcaption>On NSE, it gained 7.40 per cent to  <span class=\"webrupee\">₹</span>62.40 -- its 52-week high.</figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"The company's first plant in Andhra Pradesh will have a capacity to manufacture 4,800 buses per annum. (Mint)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/ashok-k6R--621x414@LiveMint_1613719236264.JPG\" src=\"https://images.livemint.com/img/2021/02/19/600x338/ashok-k6R--621x414@LiveMint_1613719236264.JPG\" style=\"vertical-align: middle;\" title=\"The company's first plant in Andhra Pradesh will have a capacity to manufacture 4,800 buses per annum. (Mint)\"/><figcaption>The company's first plant in Andhra Pradesh will have a capacity to manufacture 4,800 buses per annum. <strong>(Mint)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"Hachigo will remain on the board, Japan's second-biggest automaker by sales (REUTERS)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/2021-02-17T094625Z_1_LYNXMPEH1G0LA_RTROPTP_3_HONDA-CEO_1613715690741_1613715700464.JPG\" src=\"https://images.livemint.com/img/2021/02/19/600x338/2021-02-17T094625Z_1_LYNXMPEH1G0LA_RTROPTP_3_HONDA-CEO_1613715690741_1613715700464.JPG\" style=\"vertical-align: middle;\" title=\"Hachigo will remain on the board, Japan's second-biggest automaker by sales (REUTERS)\"/><figcaption>Hachigo will remain on the board, Japan's second-biggest automaker by sales <strong>(REUTERS)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"DCCDL exercised the first right of refusal to acquire Hines' stake (MINT_PRINT)\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/0ef84c0c-67a1-11eb-af56-581e788aaf84_1613715057543_1613715105425.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/0ef84c0c-67a1-11eb-af56-581e788aaf84_1613715057543_1613715105425.jpg\" style=\"vertical-align: middle;\" title=\"DCCDL exercised the first right of refusal to acquire Hines' stake (MINT_PRINT)\"/><figcaption>DCCDL exercised the first right of refusal to acquire Hines' stake <strong>(MINT_PRINT)</strong></figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"Cairn had initiated an international arbitration after Indian government in 2014 used a two-year old law to raise a Rs10,247 crore demand on a decade old internal reorganisation of the company’s unit in the country.\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/cairn-kOMB--621x414@LiveMint_1613714676304.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/cairn-kOMB--621x414@LiveMint_1613714676304.jpg\" style=\"vertical-align: middle;\" title=\"Cairn had initiated an international arbitration after Indian government in 2014 used a two-year old law to raise a Rs10,247 crore demand on a decade old internal reorganisation of the company’s unit in the country.\"/><figcaption>Cairn had initiated an international arbitration after Indian government in 2014 used a two-year old law to raise a Rs10,247 crore demand on a decade old internal reorganisation of the company’s unit in the country.</figcaption></figure>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<figure data-vars-mediatype=\"image\"><img alt=\"Saugata Gupta, managing director and chief executive, Marico Ltd. Photo: Abhijit Bhatlekar/Mint\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/Saugata-Gupta-kOpC--621x414@LiveMint_1613713582306.JPG\" src=\"https://images.livemint.com/img/2021/02/19/600x338/Saugata-Gupta-kOpC--621x414@LiveMint_1613713582306.JPG\" style=\"vertical-align: middle;\" title=\"Saugata Gupta, managing director and chief executive, Marico Ltd. Photo: Abhijit Bhatlekar/Mint\"/><figcaption>Saugata Gupta, managing director and chief executive, Marico Ltd. Photo: Abhijit Bhatlekar/Mint</figcaption></figure>]\n",
      "[<figure data-vars-mediatype=\"image\"><img alt=\"Walmart said it would raise pay for hourly US workers to an average above $15 an hour\" data-src=\"https://images.livemint.com/img/2021/02/19/600x338/S1-JI171_walmar_OR_20210218093240_1613706903839_1613706912061.jpg\" src=\"https://images.livemint.com/img/2021/02/19/600x338/S1-JI171_walmar_OR_20210218093240_1613706903839_1613706912061.jpg\" style=\"vertical-align: middle;\" title=\"Walmart said it would raise pay for hourly US workers to an average above $15 an hour\"/><figcaption>Walmart said it would raise pay for hourly US workers to an average above $15 an hour</figcaption></figure>, <figure id=\"inline-https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png\">\n",
      "<div class=\"pos-rel\"><img alt=\"Walmart's sales\" class=\"lozad storyEmbedImg\" data-src=\"https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png\" id=\"11613706939352\" title=\"Walmart's sales\"/><div class=\"imgbig imgicon\" onclick=\"javascript:openZoomedEmbedImage('11613706939352')\"><span>View Full Image</span></div></div><figcaption>Walmart's sales </figcaption>\n",
      "<div class=\"clearfix socialHolder Gplus icoSep\" id=\"socialHolder\" style=\"background:#fff; margin:0;\">\n",
      "<aside class=\"fl\">\n",
      "<div class=\"blankOverlay\" onclick=\"shareI(this)\"></div>\n",
      "<a class=\"icoBookmark3 iconSprite marZero bookmark-candidate bookmark_11613706804034-11613706939352\" data-vars-storyid=\"11592197731609\" id=\"bookmark_11613706939352\" onclick=\"javascript:bookmarkInfographics('11613706804034-11613706939352')\"></a>\n",
      "<div class=\"icoShare iconSprite share-candidate\" onclick=\"share(this)\">\n",
      "<div class=\"icoSec\">\n",
      "<span></span>\n",
      "<div>Share Via</div>\n",
      "<a class=\"icoFB2 iconSprite share-candidate\" data-vars-icontype=\"facebook\" data-vars-storyid=\"11613706939352\" href=\"javascript:void(0)\" onclick=\"sharePage('http://www.facebook.com/sharer/sharer.php?u=https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png'); trackEventBuild('Companies','News', 'Facebook');\" title=\"Facebook Share\"></a>\n",
      "<a class=\"icowhatsapp2 iconSprite share-candidate\" data-vars-icontype=\"whatsapp\" data-vars-storyid=\"11613706939352\" href=\"https://api.whatsapp.com/send?text=Walmart's sales - https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png %0a%0a%0aDownload mint app for latest in Business News - https://bit.ly/32XEfFE\" onclick=\"trackEventBuild('Companies','News', 'Whatsapp');\" target=\"_blank\"></a>\n",
      "<a class=\"icolinkedin iconSprite share-candidate\" data-vars-icontype=\"linkedin\" data-vars-storyid=\"11613706939352\" href=\"javascript:void(0)\" onclick=\"sharePage('https://www.linkedin.com/cws/share?url=https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png&amp;title=Walmart's sales'); trackEventBuild('Companies','News', 'Linkedin');\" target=\"_blank\" title=\"Linkedin Share\"></a>\n",
      "<a class=\"icoTwit2 iconSprite share-candidate\" data-vars-icontype=\"twitter\" data-vars-storyid=\"11613706939352\" href=\"javascript:void(0)\" onclick=\"sharePage('https://twitter.com/share?url=https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png&amp;text=Walmart promises raises for 425,000 workers after strong holiday sales'); trackEventBuild('Companies','News', 'Twitter');\" title=\"Tweet\"></a>\n",
      "</div></div>\n",
      "<a class=\"icoFB2 iconSprite share-candidate\" data-vars-icontype=\"facebook\" data-vars-storyid=\"11613706939352\" href=\"javascript:void(0)\" onclick=\"sharePage('http://www.facebook.com/sharer/sharer.php?u=https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png'); trackEventBuild('Companies','News', 'Facebook');\" title=\"Facebook Share\"></a>\n",
      "<a class=\"icowhatsapp2 iconSprite share-candidate\" data-vars-icontype=\"whatsapp\" data-vars-storyid=\"11613706939352\" href=\"https://api.whatsapp.com/send?text=Walmart's sales - https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png %0a%0a%0aDownload mint app for latest in Business News - https://bit.ly/32XEfFE\" onclick=\"trackEventBuild('Companies','News', 'Whatsapp');\" target=\"_blank\"></a>\n",
      "<a class=\"icolinkedin iconSprite share-candidate\" data-vars-icontype=\"linkedin\" data-vars-storyid=\"11613706939352\" href=\"javascript:void(0)\" onclick=\"sharePage('https://www.linkedin.com/cws/share?url=https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png&amp;title=Walmart's sales'); trackEventBuild('Companies','News', 'Linkedin');\" target=\"_blank\" title=\"Linkedin Share\"></a>\n",
      "<a class=\"icoTwit2 iconSprite share-candidate\" data-vars-icontype=\"twitter\" data-vars-storyid=\"11613706939352\" href=\"javascript:void(0)\" onclick=\"sharePage('https://twitter.com/share?url=https://www.livemint.com/companies/news/walmart-promises-raises-for-425-000-workers-after-strong-holiday-sales-11613706804034.html?inline=https://images.livemint.com/img/2021/02/19/original/OG-FR141_WALMAR_4U_20210218092528_1613706938808.png&amp;text=Walmart promises raises for 425,000 workers after strong holiday sales'); trackEventBuild('Companies','News', 'Twitter');\" title=\"Tweet\"></a>\n",
      "</aside>\n",
      "</div>\n",
      "</figure>]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 1: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-25c5d02dba66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;31m# #     print(result)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;31m#     result.to_excel(r'C:\\Users\\admin\\Desktop\\News_scrap\\news_scrape_data_auto.xlsx', index = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m \u001b[0mAuto_news_update_money\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-156-25c5d02dba66>\u001b[0m in \u001b[0;36mAuto_news_update_money\u001b[1;34m()\u001b[0m\n\u001b[0;32m    182\u001b[0m                              \u001b[1;34m'TITLE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtitle_cont\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                              \u001b[1;34m'CREATE_DATETIME'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mcretd_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                              \u001b[1;34m'THUMB_IMAGE'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlisttostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                              \u001b[1;34m'FROM_DATE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcurrent_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                              \u001b[1;34m'TO_DATE'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdays_after\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-25c5d02dba66>\u001b[0m in \u001b[0;36mlisttostring\u001b[1;34m(img_link)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                     \u001b[0mimg_str\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m     \u001b[1;31m#             print(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;31m#                 print(listtostring(img_link))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 1: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "def Auto_news_update_money():\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import mechanicalsoup\n",
    "    browser = mechanicalsoup.StatefulBrowser()\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import xlwt \n",
    "    from xlwt import Workbook\n",
    "    import pandas as pd\n",
    "    \n",
    "    url1 = \"https://www.moneycontrol.com/news/business/ipo/\"\n",
    "    # browser.open(url)\n",
    "    r  = requests.get(url1)\n",
    "    \n",
    "    soup1 = BeautifulSoup(r.content)\n",
    "    # print(soup)\n",
    "    links1 = soup1.find_all(\"a\")\n",
    "    key_word1 = [\"Angel Broking\", \"IPO\"]\n",
    "    \n",
    "    div1 = soup1.find_all(\"div\", {\"class\": \"fleft\"})\n",
    "\n",
    "    url1 = []\n",
    "    for ul in div1:\n",
    "        for li in ul.find_all('li'): \n",
    "            for h1 in li.find_all('h2'):\n",
    "                for link in h1.find_all('a'):\n",
    "                    url1.append(link.get('href'))\n",
    "    #                 print(url)\n",
    "    news1=[]   \n",
    "    # print(len(url))\n",
    "    for L in url1:\n",
    "        t1 = requests.get(L)\n",
    "    #     print(t.content)\n",
    "        soups1 = BeautifulSoup(t1.content)\n",
    "        for word in key_word1:\n",
    "\n",
    "            if word in str(t1.content):\n",
    "    #             print(x)\n",
    "                body_cont1 = soups1.find_all(\"div\", {\"class\" : \"article_consum_wrapper\"})\n",
    "                title_cont1 = soups1.find_all(\"h1\", {\"class\" : \"article_title\"})[0].text.strip()\n",
    "                shrt_desc1 = soups1.find_all(\"h2\", {\"class\" : \"article_desc\"})[0].text.strip()\n",
    "                cretd_date1 = soups1.find_all(\"div\", {\"class\" : \"article_schedule\"})[0].text.strip()\n",
    "\n",
    "                long_descrptn1 = soups1.find_all(\"div\", {\"class\" : \"content_wrapper arti-flow\"})[0].text.strip()\n",
    "                img_link1=[]\n",
    "                image_url1 = soups1.find_all((\"div\",{\"class\" : \"content_wrapper arti-flow\"})[0])\n",
    "                for item in image_url1:\n",
    "                        for image in item(\"div\",{\"class\" : \"article_image\"}):\n",
    "                            for image_link1 in image('img'):\n",
    "                                    img_link1.append(image_link1.get('data-src'))\n",
    "\n",
    "                image_url_link1 = list(dict.fromkeys(img_link1))\n",
    "                def listtostring(image_url_link1):\n",
    "\n",
    "                    img_str= \"\"\n",
    "                    return (img_str.join(image_url_link1))\n",
    "    #     #         print(listtostring(image_url_link))\n",
    "                auth_nam1=[]\n",
    "                author_name = soups1.find_all(\"div\", {\"class\" : \"article_author\"})\n",
    "                for x in author_name:\n",
    "                    for text in x(\"a\"):\n",
    "                            auth_nam1.append(text.get(\"title\"))\n",
    "    #                     auth_nam.append(text.get('title'))\n",
    "    #             print(auth_nam)   \n",
    "    #             for text in soups.find_all(\"a\"):\n",
    "    #                 print(text)\n",
    "    #                 for author in soups.find_all(\"title\"):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #             content = '<div> <h3 id=\"title\">'+str(title_cont)+'</h3></div> <div> <p class=\"news-iner-para\" id=\"sub-ttl\">'+str(shrt_desc)+'</p> </div> <div class=\"update-news\"> <div> <div class=\"col-sm-8 col-md-8\"> <p class=\"news-iner-para\" style=\"margin-left: -1rem;\" class=\"news-para\">'+str(cretd_date)+'</p> </div> </div> </div> <div class=\"news-pic\"> <img src=\"'+str(image_url_link)+'\" width=\"100%\"> </div> <div class=\"news-details\"> <p id=\"news_items\" class=\"news-iner-para\"> '+str(long_descrptn)+' </p> </div> </div>'\n",
    "\n",
    "    #     #         print(image_url_link)\n",
    "\n",
    "                from datetime import date, timedelta\n",
    "\n",
    "                current_date1 = date.today().isoformat()\n",
    "                days_after1 = (date.today()+timedelta(days=3)).isoformat()\n",
    "#                 print(L)   \n",
    "                news1.append({'SHORT_DESCRIPTION' : shrt_desc1,\n",
    "                             'LONG_DESCRIPTION' : long_descrptn1,\n",
    "                             'TITLE': title_cont1,\n",
    "                             'CREATE_DATETIME' : cretd_date1,\n",
    "                             'THUMB_IMAGE' : listtostring(image_url_link1),\n",
    "                             'FROM_DATE': current_date1,\n",
    "                             'TO_DATE' : days_after1,\n",
    "                             'author_name' : auth_nam1,\n",
    "                             'CATEGORY' : '',\n",
    "                             'SOURCE':'Money Control',\n",
    "                             'WEBSITE_LINK':L\n",
    "                            })\n",
    "                \n",
    "            break\n",
    "#             print(news1)\n",
    "    df1 = pd.DataFrame(news1)\n",
    "    \n",
    "#     df.to_excel(r'C:\\Users\\admin\\Desktop\\News_scrap\\news_scrape_data_mony_contrl.xlsx', index = False)     \n",
    "# Auto_news_update_money()\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import mechanicalsoup\n",
    "    browser = mechanicalsoup.StatefulBrowser()\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    # print(df1)\n",
    "    website_link = \"https://www.livemint.com/companies/news\"\n",
    "    # print(website_link)\n",
    "    # browser.open(url)\n",
    "    r  = requests.get(website_link)\n",
    "    # print(r)\n",
    "    join_url = \"https://www.livemint.com\"\n",
    "\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    # print(soup)\n",
    "    links = soup.find_all(\"a\")\n",
    "    # print(links)\n",
    "    key_word = [\"Angel Broking\", \"IPO\"]\n",
    "\n",
    "    div = soup.find_all(\"div\", {\"class\": \"listView\"})\n",
    "    # print(div)\n",
    "    url = []\n",
    "    for classes in div:\n",
    "        for link in classes.find_all(\"div\", {\"class\": \"headlineSec\"}):\n",
    "                for art_link in link.find_all(\"h2\"):\n",
    "                    for exct_art_link in art_link.find_all(\"a\"):\n",
    "                        url.append(join_url + exct_art_link.get('href'))\n",
    "    # print(url)\n",
    "    news=[]\n",
    "    for x in url:\n",
    "        t = requests.get(x)\n",
    "        soups = BeautifulSoup(t.content)\n",
    "    #     print(t.content)\n",
    "        for word in key_word:\n",
    "            if word in str(t.content):\n",
    "    #             print(x)\n",
    "                title_cont = soups.find_all(\"h1\", {\"class\" : \"headline\"})[0].text.strip()\n",
    "                short_description=''\n",
    "                shrt_desc = soups.find_all(\"section\", {\"class\" : \"cardHolder open\"})[0].text.strip()\n",
    "                for ul in soups.find_all(\"ul\", {\"class\" : \"highlights\"}):\n",
    "                    for li in ul.find_all(\"li\", recursive=False):\n",
    "                        short_description = li.getText()\n",
    "    #                     print(short_description)\n",
    "                cretd_date = soups.find_all(\"span\", {\"class\" : \"articleInfo\"})[0].text.strip()\n",
    "    #             print(cretd_date.strip())\n",
    "                long_descrptn = soups.find_all(\"div\", {\"class\" : \"mainArea\"})[0].text.strip()\n",
    "                regex = r':\\s*\\n+'\n",
    "                subst = \": \"\n",
    "                long_desc= []\n",
    "                for line in re.sub(regex, subst, long_descrptn, 0, re.MULTILINE).split('\\n'):\n",
    "                     if line != '':\n",
    "                        long_desc.append(line.strip())        \n",
    "    # #             print(long_desc[0])        \n",
    "                img_link=[]        \n",
    "                image_url = soups.find_all((\"figure\",{\"data-vars-mediatype\" : \"image\"})[0])\n",
    "                print(image_url)\n",
    "                for link in image_url:\n",
    "                    for image_link in link('img'):\n",
    "                        img_link.append(image_link.get('src'))\n",
    "                def listtostring(img_link):\n",
    "\n",
    "                    img_str= \"\"\n",
    "                    return (img_str.join(img_link))\n",
    "    #             print(x)\n",
    "#                 print(listtostring(img_link))\n",
    "                author_name = soups.find_all(\"span\", {\"class\" : \"articleInfo author\"})[0].text.strip()\n",
    "    #             print(author_name)\n",
    "\n",
    "    # #             content = '<div> <h3 id=\"title\">'+str(title_cont)+'</h3></div> <div> <p class=\"news-iner-para\" id=\"sub-ttl\">'+str(short_description)+'</p> </div> <div class=\"update-news\"> <div> <div class=\"col-sm-8 col-md-8\"> <p class=\"news-iner-para\" style=\"margin-left: -1rem;\" class=\"news-para\">'+str(cretd_date.strip())+'</p> </div> </div> </div> <div class=\"news-pic\"> <img src=\"'+str(listtostring(img_link))+'\" width=\"100%\"> </div> <div class=\"news-details\"> <p id=\"news_items\" class=\"news-iner-para\"> '+str(long_desc[0])+' </p> </div> </div>'\n",
    "\n",
    "                from datetime import date, timedelta\n",
    "\n",
    "                current_date = date.today().isoformat()\n",
    "                days_after = (date.today()+timedelta(days=3)).isoformat()            \n",
    "\n",
    "                news.append({'SHORT_DESCRIPTION' : short_description,\n",
    "                             'LONG_DESCRIPTION' : long_desc[0],\n",
    "                             'TITLE': title_cont,\n",
    "                             'CREATE_DATETIME' : cretd_date.strip(),\n",
    "                             'THUMB_IMAGE' : listtostring(img_link),\n",
    "                             'FROM_DATE': current_date,\n",
    "                             'TO_DATE' : days_after,\n",
    "                             'author_name' : author_name,\n",
    "                             'CATEGORY' : '',\n",
    "                             'SOURCE':'Live Mint',\n",
    "                             'WEBSITE_LINK':x\n",
    "                            })\n",
    "\n",
    "                break     \n",
    "    #             print(news)\n",
    "\n",
    "    df2 = pd.DataFrame(news)\n",
    "    \n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import mechanicalsoup\n",
    "    browser = mechanicalsoup.StatefulBrowser()\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    \n",
    "    website_link2 = \"https://economictimes.indiatimes.com/markets/ipo\"\n",
    "    # browser.open(url)\n",
    "    r2  = requests.get(website_link2)\n",
    "#     print(r2)\n",
    "    join_url2 = \"https://economictimes.indiatimes.com\"\n",
    "    \n",
    "    \n",
    "    soup2 = BeautifulSoup(r2.content)\n",
    "    # print(soup)\n",
    "    links2 = soup2.find_all(\"a\")\n",
    "    # print(links)\n",
    "    key_word2 = [\"Angel Broking\", \"IPO\"]\n",
    "    \n",
    "    div2 = soup2.find_all(\"section\", {\"class\" : \"ipoData\"})\n",
    "    # print(div)\n",
    "    url2 = []\n",
    "    for classes in div2:\n",
    "        for links in classes.find_all(\"div\",{\"class\" : \"flr ipo_sec1\"}):\n",
    "            for ul in links.find_all('ul'):\n",
    "                for li in ul.find_all('li'):\n",
    "                    for link in li.find_all('a'):\n",
    "                        url2.append(join_url2 + link.get('href'))\n",
    "#                         print(url)\n",
    "\n",
    "    news=[]\n",
    "    for x in url2:\n",
    "        t = requests.get(x)\n",
    "        soups = BeautifulSoup(t.content)\n",
    "#         print(soups)\n",
    "        for word in key_word2:\n",
    "            if word in str(t.content):\n",
    "                title_cont = soups.find_all(\"h1\", {\"class\" : \"artTitle font_faus\"})[0].text.strip()\n",
    "                short_description=''\n",
    "                shrt_desc = soups.find_all(\"div\", {\"class\" : \"artSyn bgPink\"})[0].text.strip()\n",
    "                for text in soups.find_all(\"h2\", {\"class\" : \"summary\"}):\n",
    "                    short_description = text.getText()\n",
    "    #                 print(short_description)\n",
    "                cretd_date = soups.find_all(\"time\")[0].text.strip()\n",
    "                long_descrptn = soups.find_all(\"div\", {\"class\" : \"pageContent flt\"}, {\"data-brcount\" : \"21\"})[0].text.strip()\n",
    "                regex = r':\\s*\\n+'\n",
    "                subst = \": \"\n",
    "                long_desc= []\n",
    "                for line in re.sub(regex, subst, long_descrptn, 0, re.MULTILINE).split('\\n'):\n",
    "                     if line != '':\n",
    "                        long_desc.append(line.strip())\n",
    "    #             print(long_desc[0])\n",
    "                img_link=[]\n",
    "                image_url = soups.find_all((\"figure\",{\"class\" : \"artImg\"})[0])\n",
    "                for link in image_url:\n",
    "                    for image_link in link('img'):\n",
    "                        img_link.append(image_link.get('src'))\n",
    "    #                     print(img_link)\n",
    "                def listtostring(img_link):\n",
    "\n",
    "                    img_str= \"\"\n",
    "                    return (img_str.join(img_link))\n",
    "    #             print(listtostring(img_link))\n",
    "    #             content = '<div> <h3 id=\"title\">'+str(title_cont)+'</h3></div> <div> <p class=\"news-iner-para\" id=\"sub-ttl\">'+str(short_description)+'</p> </div> <div class=\"update-news\"> <div> <div class=\"col-sm-8 col-md-8\"> <p class=\"news-iner-para\" style=\"margin-left: -1rem;\" class=\"news-para\">'+str(cretd_date.strip())+'</p> </div> </div> </div> <div class=\"news-pic\"> <img src=\"'+str(listtostring(img_link))+'\" width=\"100%\"> </div> <div class=\"news-details\"> <p id=\"news_items\" class=\"news-iner-para\"> '+str(long_desc[0])+' </p> </div> </div>'\n",
    "\n",
    "                from datetime import date, timedelta\n",
    "\n",
    "                current_date = date.today().isoformat()\n",
    "                days_after = (date.today()+timedelta(days=3)).isoformat()\n",
    "\n",
    "                news.append({'SHORT_DESCRIPTION' : short_description,\n",
    "                             'LONG_DESCRIPTION' : long_desc[0],\n",
    "                             'TITLE': title_cont,\n",
    "                             'CREATE_DATETIME' : cretd_date.strip(),\n",
    "                             'THUMB_IMAGE' : listtostring(img_link),\n",
    "                             'FROM_DATE': current_date,\n",
    "                             'TO_DATE' : days_after,\n",
    "                             'CATEGORY' : '',\n",
    "                             'SOURCE':'India Times',\n",
    "                             'WEBSITE_LINK':x\n",
    "                            })\n",
    "\n",
    "                break\n",
    "\n",
    "    \n",
    "    df3 = pd.DataFrame(news)\n",
    "    print(df3)\n",
    "    \n",
    "#     print(df2)\n",
    "    result = pd.concat([df1, df2, df3], axis=0, keys=[\"Money Control\", \"Live Mint\", \"India Times\"])\n",
    "# #     print(result)\n",
    "#     result.to_excel(r'C:\\Users\\admin\\Desktop\\News_scrap\\news_scrape_data_auto.xlsx', index = True)\n",
    "Auto_news_update_money()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HOST = \"\"\n",
    "DB_NAME = \"\"\n",
    "DB_USER = \"\"\n",
    "DB_PASS = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=unlistedkart_db user=postgres password=venkiravi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"unlistedkart_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"venkirav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"unlistedkart\", user = \"postgres\", password = \"venkirav\", host = \"127.0.0.1\", port = \"5432\")\n",
    "\n",
    "print \"Opened database successfully\"\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    },
    {
     "ename": "UndefinedColumn",
     "evalue": "column \"shrt_desc1\" does not exist\nLINE 16:                         VALUES (shrt_desc1,long_descrptn1,ti...\n                                         ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-4ca6c1186398>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                         VALUES (shrt_desc1,long_descrptn1,title_cont1, cretd_date1,\n\u001b[0;32m     26\u001b[0m                                 \u001b[0mlisttostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_url_link1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_date1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdays_after1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                                 auth_nam1,1, 'Money Control', L)''')\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m# cur.execute('''INSERT INTO PRODUCTION.NEWS_VIDEOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#                         (TITLE,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUndefinedColumn\u001b[0m: column \"shrt_desc1\" does not exist\nLINE 16:                         VALUES (shrt_desc1,long_descrptn1,ti...\n                                         ^\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(database = \"dbmaster\", user = \"dbmasteruser\", \n",
    "                        password = \"+zO!J!,l~;qK3(r(VsLKAe(&}R`RF$7c\", \n",
    "                        host = \"ls-dc50b6cbd6cf43d6316762fdf471c76eba810680.ccsyoalnsfyi.ap-south-1.rds.amazonaws.com\", \n",
    "                        port = \"5432\")\n",
    "print (\"Opened database successfully\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('''INSERT \n",
    "                            INTO \n",
    "                        news(   \n",
    "                            SHORT_DESCRIPTION,\n",
    "                            LONG_DESCRIPTION,\n",
    "                            TITLE,\n",
    "                            CREATE_DATETIME,\n",
    "                            THUMB_IMAGE,\n",
    "                            FROM_DATE,\n",
    "                            TO_DATE,\n",
    "                            AUTHOR,\n",
    "                            \"newsCategoryId\",\n",
    "                            SOURCE,\n",
    "                            WEBSITE_LINK\n",
    "                        )\n",
    "                        VALUES (shrt_desc1,long_descrptn1,title_cont1, cretd_date1,\n",
    "                                listtostring(image_url_link1), current_date1, days_after1, \n",
    "                                auth_nam1,1, 'Money Control', L)''')\n",
    "# cur.execute('''INSERT INTO PRODUCTION.NEWS_VIDEOS\n",
    "#                         (TITLE,\n",
    "#                         SHORT_DESCRIPTION,\n",
    "#                         THUMB_IMAGE,\n",
    "#                         CREATED_DATE,\n",
    "#                         FROM_DATE,\n",
    "#                         TO_DATE,\n",
    "#                         VIDEO_URL,\n",
    "#                         REFFERD_BY,\n",
    "#                         SOURCE,\n",
    "#                         WEBSITE_LINK) \n",
    "#                         VALUES ?''')\n",
    "print(\"News scraped successfully\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "\n",
    "# conn = psycopg2.connect(database = \"testdb\", user = \"postgres\", password = \"pass123\", host = \"127.0.0.1\", port = \"5432\")\n",
    "# print \"Opened database successfully\"\n",
    "\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# cur.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "#       VALUES (1, 'Paul', 32, 'California', 20000.00 )\");\n",
    "\n",
    "# cur.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "#       VALUES (2, 'Allen', 25, 'Texas', 15000.00 )\");\n",
    "\n",
    "# cur.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "#       VALUES (3, 'Teddy', 23, 'Norway', 20000.00 )\");\n",
    "\n",
    "# cur.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "#       VALUES (4, 'Mark', 25, 'Rich-Mond ', 65000.00 )\");\n",
    "\n",
    "# conn.commit()\n",
    "# print \"Records created successfully\";\n",
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
